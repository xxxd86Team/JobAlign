import streamlit as st
import pandas as pd
import json
import plotly.express as px
from PyPDF2 import PdfReader
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import io
import time
from openai import OpenAI
from PIL import Image
import pytesseract

# ================= 1. å…¨å±€é…ç½®ä¸çŠ¶æ€ç®¡ç† =================
st.set_page_config(
    page_title="JobAlign AI Pro",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– Session State
if 'analyzed' not in st.session_state:
    st.session_state.analyzed = False
if 'result_json' not in st.session_state:
    st.session_state.result_json = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""


# ================= 2. æ ¸å¿ƒå¤„ç†å·¥å…·ç±» =================

class DocumentHandler:
    @staticmethod
    def extract_text(file):
        """
        ç»Ÿä¸€å¤„ç† PDF / Word / æ–‡æœ¬ / å›¾ç‰‡ çš„æ–‡æœ¬æå–
        æ”¯æŒï¼š
        - .pdf
        - .doc / .docx
        - .txt
        - å›¾ç‰‡ï¼š.png / .jpg / .jpeg / .bmp / .tiff / .gifï¼ˆé€šè¿‡ OCR è¯†åˆ«ï¼‰
        """
        text = ""
        try:
            filename = getattr(file, "name", "")
            ext = filename.split(".")[-1].lower() if "." in filename else ""

            # ç¡®ä¿æŒ‡é’ˆåœ¨æ–‡ä»¶å¼€å¤´
            try:
                file.seek(0)
            except Exception:
                pass

            if ext == 'pdf':
                reader = PdfReader(file)
                for page in reader.pages:
                    content = page.extract_text()
                    if content:
                        text += content + "\n"

            elif ext in ['docx', 'doc']:
                doc = Document(file)
                text = "\n".join([para.text for para in doc.paragraphs])

            elif ext == 'txt':
                text = file.getvalue().decode("utf-8")

            elif ext in ['png', 'jpg', 'jpeg', 'bmp', 'tiff', 'gif']:
                # å›¾ç‰‡ OCR è¯†åˆ«
                file_bytes = file.read()
                image = Image.open(io.BytesIO(file_bytes))
                # å¦‚æœ¬æœºæœ‰ä¸­æ–‡è¯­è¨€åŒ…ï¼Œå¯ä½¿ç”¨ lang='chi_sim+eng'
                text = pytesseract.image_to_string(image,lang='chi_sim+eng')

            else:
                # å…œåº•ï¼šå°è¯•æ–‡æœ¬æ–¹å¼è¯»å–
                try:
                    text = file.getvalue().decode("utf-8")
                except Exception:
                    text = ""

            return text
        except Exception as e:
            return f"Error: æ–‡ä»¶è§£æå¤±è´¥ ({str(e)})"


class WordGenerator:
    @staticmethod
    def create_docx_from_markdown(markdown_text):
        """å°† Markdown æ ¼å¼çš„ç®€å†è‰ç¨¿è½¬æ¢ä¸ºæ ¼å¼åŒ–çš„ Word æ–‡æ¡£"""
        doc = Document()

        # è®¾ç½®åŸºç¡€æ ·å¼
        style = doc.styles['Normal']
        font = style.font
        font.name = 'å¾®è½¯é›…é»‘'
        font.size = Pt(11)

        lines = markdown_text.split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # å¤„ç†ä¸€çº§æ ‡é¢˜ (# Title)
            if line.startswith('# '):
                p = doc.add_heading(line[2:], level=1)
                p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

            # å¤„ç†äºŒçº§æ ‡é¢˜ (## Title)
            elif line.startswith('## '):
                p = doc.add_heading(line[3:], level=2)

            # å¤„ç†ä¸‰çº§æ ‡é¢˜ (### Title)
            elif line.startswith('### '):
                p = doc.add_heading(line[4:], level=3)

            # å¤„ç†åˆ—è¡¨é¡¹ (- Item / * Item)
            elif line.startswith('- ') or line.startswith('* '):
                p = doc.add_paragraph(line[2:], style='List Bullet')

            # å¤„ç†åŠ ç²— (**Text**) - ç®€å•å¤„ç†ï¼Œä»…å»é™¤æ ‡è®°
            elif '**' in line:
                clean_line = line.replace('**', '')
                doc.add_paragraph(clean_line)

            # æ™®é€šæ–‡æœ¬
            else:
                doc.add_paragraph(line)

        # ä¿å­˜åˆ°å†…å­˜æµ
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer


# ================= 3. AI äº¤äº’é€»è¾‘ =================

MOCK_DATA = {
    "total_score": 78,
    "dimensions": {
        "æŠ€èƒ½åŒ¹é…åº¦": 82,
        "ç»éªŒç›¸å…³æ€§": 75,
        "è¡Œä¸šå¥‘åˆåº¦": 70,
        "è¡¨è¾¾ä¸äº®ç‚¹": 88
    },
    "highlights": [
        "æ¼”ç¤ºæ¨¡å¼ï¼šå·²æœ‰ AI/å¤§æ¨¡å‹ç›¸å…³é¡¹ç›®ï¼Œå’Œ AI äº§å“/æ™ºèƒ½åˆ†æå²—ä½é«˜åº¦ç›¸å…³ã€‚",
        "æ¼”ç¤ºæ¨¡å¼ï¼šå…·å¤‡ä¸€å®š Python / æ•°æ®åˆ†æåŸºç¡€ï¼Œæ–¹ä¾¿åç»­å‘æ•°æ®äº§å“æˆ–æ™ºèƒ½åˆ†ææ–¹å‘å»¶å±•ã€‚"
    ],
    "gaps": [
        "æ¼”ç¤ºæ¨¡å¼ï¼šç®€å†ä¸­ç¼ºå°‘ç³»ç»Ÿæ€§çš„æŒ‡æ ‡è®¾è®¡ä¸ä¸šåŠ¡ç»“æœé‡åŒ–æè¿°ã€‚",
        "æ¼”ç¤ºæ¨¡å¼ï¼šç¼ºå°‘å¯¹åä½œæ–¹å¼ã€è·¨éƒ¨é—¨æ²Ÿé€šçš„å…·ä½“æ¡ˆä¾‹è¯´æ˜ã€‚"
    ],
    "suggestions": [
        {
            "section": "é¡¹ç›®ç»å†",
            "original": "å‚ä¸é£å‘ç›‘æ§ Agent é¡¹ç›®ã€‚",
            "problem": "æè¿°è¿‡äºç¬¼ç»Ÿï¼Œçœ‹ä¸å‡ºä¸šåŠ¡èƒŒæ™¯ã€ä½ çš„èŒè´£å’Œç»“æœã€‚",
            "rewrite": "ä¸»å¯¼é£å‘ç›‘æ§ Agent éœ€æ±‚åˆ†æä¸PRDæ’°å†™ï¼Œè¦†ç›–æˆ˜ç•¥/è¡Œä¸š/äº§å“ç­‰6ä¸ªç»´åº¦çš„ä¿¡æ¯æºï¼Œå°†ç«å“æƒ…æŠ¥æ•´ç†è€—æ—¶ä»1å¤©ç¼©çŸ­è‡³2å°æ—¶ï¼Œä¸ºè€æ¿å‘¨ä¾‹ä¼šæä¾›ç»“æ„åŒ–å¯¹æ‰‹æƒ…æŠ¥è¾“å…¥ã€‚"
        },
        {
            "section": "æŠ€èƒ½",
            "original": "ç†Ÿç»ƒä½¿ç”¨ Officeã€‚",
            "problem": "è¡¨è¿°è¿‡æ³›ï¼Œä¸ç›®æ ‡å²—ä½çš„å…³é”®èƒ½åŠ›ç¼ºä¹å…³è”ã€‚",
            "rewrite": "ç†Ÿç»ƒä½¿ç”¨ Excel / Pandas è¿›è¡Œæ•°æ®æ¸…æ´—ä¸æ¼æ–—åˆ†æï¼Œå…·å¤‡åŸºç¡€ SQL æŸ¥è¯¢èƒ½åŠ›ï¼Œå¯ç‹¬ç«‹å®Œæˆç®€å†æ•°æ®ä¸ä¸šåŠ¡æ—¥å¿—æ•°æ®çš„ç»“æ„åŒ–å¤„ç†ã€‚"
        }
    ],
    "draft_resume": """# æ¼”ç¤ºç®€å†
## ä¸ªäººç®€ä»‹
æˆ‘æ­£åœ¨å‘ AI äº§å“ / æ•°æ®åˆ†ææ–¹å‘å‘å±•ï¼Œå…·å¤‡åŸºç¡€äº§å“æ–¹æ³•è®ºå’Œæ•°æ®åˆ†æèƒ½åŠ›ï¼Œå·²ç»é€šè¿‡å¤šé¡¹é¡¹ç›®å®è·µç†Ÿæ‚‰ã€Œéœ€æ±‚åˆ†æ â†’ æ–¹æ¡ˆè®¾è®¡ â†’ é¡¹ç›®è½åœ° â†’ ç»“æœå¤ç›˜ã€çš„å®Œæ•´é—­ç¯ã€‚

## æ•™è‚²ç»å†
- **æŸæŸå¤§å­¦ æœ¬ç§‘ Â· ä¸“ä¸šï¼šXXX**ï¼ˆ201X - 202Xï¼‰
  - ç›¸å…³è¯¾ç¨‹ï¼šæ•°æ®åˆ†æã€ç»Ÿè®¡å­¦åŸºç¡€ã€æ•°æ®åº“åŸç†ã€è®¡ç®—æœºåŸºç¡€

## å®ä¹  / é¡¹ç›®ç»å†
- **é£å‘ç›‘æ§ Agent é¡¹ç›®ï½œAI äº§å“å®ä¹  / ä¸ªäººé¡¹ç›®**
  - èƒŒæ™¯ï¼šå…¬å¸ç¼ºä¹ç³»ç»Ÿçš„ç«å“ä¸è¡Œä¸šä¿¡æ¯æ”¶é›†æœºåˆ¶ï¼Œæƒ…æŠ¥ä¾èµ–äººå·¥æœç´¢ä¸é›¶æ•£è®°å½•ã€‚
  - èŒè´£ï¼šä¸»å¯¼é£å‘ç›‘æ§ Agent çš„éœ€æ±‚åˆ†æã€PRDæ’°å†™ä¸æ ¸å¿ƒæµç¨‹è®¾è®¡ã€‚
  - æ–¹æ¡ˆï¼š
    - è®¾è®¡æˆ˜ç•¥ / è¡Œä¸š / è´¢åŠ¡ / äº§å“ / æ‹›æŠ•æ ‡ / å£ç¢‘ 6ä¸ªç»´åº¦çš„ç›‘æ§æ¡†æ¶ï¼›
    - å®šä¹‰å¤š Agent ååŒæ£€ç´¢ä¸èšåˆè§„åˆ™ï¼Œæ­å»ºèˆ†æƒ…ä¸æƒ…æŠ¥æ•°æ®çš„åˆæ­¥ç»“æ„åŒ–æ–¹æ¡ˆã€‚
  - ç»“æœï¼š
    - å°†ç«å“æƒ…æŠ¥æ•´ç†è€—æ—¶ä»1å¤©ç¼©çŸ­è‡³2å°æ—¶ï¼›
    - æ”¯æŒè€æ¿åœ¨å‘¨ä¾‹ä¼šä¸­æ›´ç³»ç»Ÿåœ°è¯„ä¼°ç«å¯¹ç­–ç•¥ä¸è¡Œä¸šåŠ¨å‘ã€‚
  - å·¥å…·ï¼šCoze / è…¾è®¯å…ƒå®ã€å¤šAgentç¼–æ’ã€Notionã€Excel

- **JobAlign AI ç®€å†åŒ¹é…ä¸æˆé•¿è§„åˆ’å·¥å…·ï½œä¸ªäººé¡¹ç›®**
  - èƒŒæ™¯ï¼šæ±‚èŒè€…å¾ˆéš¾ç†è§£ JD éœ€æ±‚ã€è¯„ä¼°è‡ªèº«åŒ¹é…åº¦å¹¶è§„åˆ’ä¸‹ä¸€æ­¥å­¦ä¹ ã€‚
  - èŒè´£ï¼šä»0åˆ°1è®¾è®¡å¹¶å®ç°ç®€å†ä¸Šä¼ è§£æã€JDå¯¹æ¯”ã€åŒ¹é…æŠ¥å‘Šã€å­¦ä¹ è§„åˆ’ä¸å²—ä½æ¨èçš„å®Œæ•´æµç¨‹ã€‚
  - æ–¹æ¡ˆï¼š
    - ä½¿ç”¨ Streamlit æ„å»ºå‰ç«¯ç•Œé¢ï¼Œæ”¯æŒ PDF / Word / å›¾ç‰‡ç®€å†ä¸å¤šä¸ª JD åŒæ—¶ä¸Šä¼ ï¼›
    - åˆ©ç”¨å¤§æ¨¡å‹ç”ŸæˆåŒ¹é…åº¦è¯„åˆ†ã€äº®ç‚¹ / ç¼ºå¤±åˆ†æã€ç®€å†æ”¹å†™å»ºè®®ä¸3-6ä¸ªæœˆæˆé•¿è·¯å¾„ã€‚
  - ç»“æœï¼š
    - å¸®åŠ©ç”¨æˆ·å¿«é€Ÿè¯†åˆ«ä¸è‡ªèº«èƒŒæ™¯æ›´å¥‘åˆçš„å²—ä½æ–¹å‘ï¼›
    - æä¾›ç»“æ„åŒ–çš„å­¦ä¹ ä¸é¡¹ç›®å®è·µå»ºè®®ï¼Œä¸ºåç»­æ±‚èŒæ‰“åŸºç¡€ã€‚
  - å·¥å…·ï¼šPythonã€Streamlitã€OpenAI / DeepSeek APIã€PyPDF2ã€pytesseract

## æŠ€èƒ½
- äº§å“ï¼šéœ€æ±‚åˆ†æã€PRDæ’°å†™ã€ç”¨æˆ·åœºæ™¯æ‹†è§£ã€UATæµ‹è¯•
- æ•°æ®ï¼šPythonï¼ˆPandasï¼‰ã€SQLåŸºç¡€ã€ç®€å•å¯è§†åŒ–ä¸æ¼æ–—åˆ†æ
- å·¥å…·ï¼šFigma / å¢¨åˆ€ã€Notionã€Excelã€Streamlit
- AIï¼šå¯¹å¤§æ¨¡å‹ã€RAGã€å¤š Agent æœ‰ä¸€å®šç†è§£ï¼Œèƒ½åŸºäºå¹³å°æ­å»ºç®€å•æ™ºèƒ½ä½“æµç¨‹

## å…¶ä»–
- æŒç»­åœ¨ CSDN / ä¸ªäººå…¬ä¼—å·è¾“å‡ºæ•°æ®ä¸ AI äº§å“ç›¸å…³å†…å®¹ï¼Œä¿æŒè‡ªæˆ‘è¿­ä»£ã€‚
""",
    "learning_plan": {
        "target_direction": "AI äº§å“ / æ•°æ®äº§å“ æ–¹å‘",
        "summary": "ç»¼åˆä½ çš„ç®€å†ä¸ç›®æ ‡ JDï¼Œæ›´æ¨èä½ åœ¨æœªæ¥3-6ä¸ªæœˆé‡ç‚¹å¼ºåŒ–ï¼šäº§å“æ–¹æ³•è®ºã€æ•°æ®åˆ†ææ€ç»´ä¸é¡¹ç›®å¤ç›˜èƒ½åŠ›ï¼Œç”¨å°‘é‡ä½†é«˜è´¨é‡çš„é¡¹ç›®æ”¯æ’‘ç®€å†ï¼Œè€Œä¸æ˜¯ç›²ç›®å †æ•°é‡ã€‚",
        "skills_to_focus": [
            "ç³»ç»ŸåŒ–çš„PRDå†™ä½œä¸éœ€æ±‚æ‹†è§£",
            "SQL + åŸºç¡€æ•°æ®åˆ†ææ€ç»´",
            "ä¸šåŠ¡æŒ‡æ ‡è®¾è®¡ä¸ç»“æœé‡åŒ–è¡¨è¾¾",
            "é¡¹ç›®å¤ç›˜ä¸ç»“æ„åŒ–è¡¨è¾¾"
        ],
        "stages": [
            {
                "name": "ç¬¬1-4å‘¨ï¼šæ‰“åŸºç¡€ï¼ˆç†è§£å²—ä½ & å¼ºåŒ–è¡¨è¾¾ï¼‰",
                "goals": [
                    "ææ¸…æ¥šAIäº§å“ / æ•°æ®äº§å“å²—ä½çš„æ—¥å¸¸ä¸æ ¸å¿ƒèƒ½åŠ›",
                    "èƒ½å†™å‡ºç»“æ„æ¸…æ™°ä¸”æœ‰é‡ç‚¹çš„PRD / é¡¹ç›®è¯´æ˜"
                ],
                "actions": [
                    "æ¯å‘¨é˜…è¯»2-3ç¯‡ AI / æ•°æ®äº§å“æ¡ˆä¾‹æ‹†è§£ï¼Œå°†æ ¸å¿ƒç»“æ„å’Œäº®ç‚¹è®°å½•ä¸‹æ¥ã€‚",
                    "é€‰1-2ä¸ªä½ å¸¸ç”¨çš„äº§å“ï¼Œå°è¯•ä»â€œé—®é¢˜-ç›®æ ‡-æ–¹æ¡ˆ-æŒ‡æ ‡â€çš„è§’åº¦å„å†™1é¡µåˆ†æã€‚"
                ]
            },
            {
                "name": "ç¬¬5-8å‘¨ï¼šæ‰“é€  1-2 ä¸ªå¯å†™è¿›ç®€å†çš„é¡¹ç›®",
                "goals": [
                    "äº§å‡ºè‡³å°‘1ä¸ªå®Œæ•´é¡¹ç›®ï¼Œå¯åœ¨ç®€å†ä¸­ç”¨1/3é¡µé‡ç‚¹æè¿°",
                    "é¡¹ç›®è¯´æ˜ä¸­èƒ½ä½“ç°â€œåšäº†ä»€ä¹ˆâ€å’Œâ€œå¸¦æ¥äº†ä»€ä¹ˆå˜åŒ–â€"
                ],
                "actions": [
                    "åŸºäº JobAlign ç­‰ç°æœ‰é¡¹ç›®ï¼Œè¡¥ä¸Šéœ€æ±‚èƒŒæ™¯ã€ç›®æ ‡ç”¨æˆ·ã€å…³é”®æŒ‡æ ‡ä¸å¤ç›˜æ€è€ƒã€‚",
                    "ç»“åˆå…¬å¼€æ•°æ®æˆ–æ¨¡æ‹Ÿæ•°æ®ï¼Œåšä¸€ä»½ç®€å•çš„æ•°æ®åˆ†ææˆ–çœ‹æ¿ï¼Œå¹¶å†™æˆå°æŠ¥å‘Šã€‚"
                ]
            },
            {
                "name": "ç¬¬9-12å‘¨ï¼šæ ¡å‡†ç®€å† & é¢„çƒ­é¢è¯•",
                "goals": [
                    "è®©ç®€å†ä¸ç›®æ ‡ JD çš„å…³é”®è¯é«˜åº¦å¯¹é½ï¼ŒåŒæ—¶ä¿æŒçœŸå®",
                    "æå‰ç†Ÿæ‚‰å¸¸è§é¢è¯•é—®æ³•å’Œé¡¹ç›®æ·±æŒ–è§’åº¦"
                ],
                "actions": [
                    "é’ˆå¯¹ 3-5 æ¡ç›®æ ‡ JDï¼Œä½¿ç”¨æœ¬å·¥å…·å¤šæ¬¡ä¼˜åŒ–ç®€å†è¡¨è¿°ï¼Œå½¢æˆ 1-2 ä»½ä¸»åŠ›ç‰ˆæœ¬ã€‚",
                    "åœ¨ç‰›å®¢ç­‰å¹³å°åˆ·åŒå²—ä½é¢ç»ï¼Œæ•´ç†é«˜é¢‘é—®é¢˜ï¼Œå¹¶ç”¨è‡ªå·±çš„é¡¹ç›®ç»ƒä¹ å›ç­”ã€‚"
                ]
            }
        ]
    },
    "resources": [
        {
            "platform": "Bç«™",
            "category": "å­¦ä¹ è§†é¢‘",
            "search_keyword": "äº§å“ç»ç† PRD å…¥é—¨ æ¡ˆä¾‹ æ‹†è§£",
            "reason": "å¸®åŠ©ä½ ç³»ç»Ÿç†è§£ PRD çš„ç»“æ„å’Œå†™æ³•ï¼Œæå‡ç®€å†ä¸­äº§å“é¡¹ç›®çš„ä¸“ä¸šåº¦ã€‚"
        },
        {
            "platform": "Bç«™",
            "category": "å­¦ä¹ è§†é¢‘",
            "search_keyword": "Python SQL æ•°æ®åˆ†æ é›¶åŸºç¡€ å®æˆ˜ é¡¹ç›®",
            "reason": "ä½ å¯¹æ•°æ®åˆ†ææœ‰å…´è¶£ï¼Œä½†ç¼ºå°‘æˆä½“ç³»é¡¹ç›®ï¼Œå¯ä»¥é€šè¿‡å®æˆ˜æ•™å­¦è¡¥é½ã€‚"
        },
        {
            "platform": "ç‰›å®¢",
            "category": "é¢è¯•ç»éªŒ",
            "search_keyword": "AI äº§å“ å®ä¹  é¢ç» 2024",
            "reason": "ç›®æ ‡ JD æ˜¯ AI / å¤§æ¨¡å‹ç›¸å…³äº§å“æ–¹å‘ï¼Œæå‰ç†Ÿæ‚‰å¸¸è§é¢è¯•é—®é¢˜å’Œè€ƒå¯Ÿç»´åº¦ã€‚"
        },
        {
            "platform": "CSDN",
            "category": "æŠ€æœ¯æ–‡ç« ",
            "search_keyword": "Streamlit ç®€å†åˆ†æ é¡¹ç›® å®æˆ˜",
            "reason": "ä½ å·²ç»åœ¨åš Streamlit ç®€å†åˆ†æå·¥å…·ï¼Œå¯ä»¥å‚è€ƒä»–äººå®è·µï¼Œä¸°å¯Œé¡¹ç›®äº®ç‚¹ã€‚"
        }
    ],
    "job_recommendations": [
        {
            "title": "AI äº§å“å®ä¹ ç”Ÿ",
            "company_type": "å¤´éƒ¨/æ–°é”äº’è”ç½‘å…¬å¸ï¼ˆç¤ºä¾‹ï¼‰",
            "location": "ä¸€çº¿ / æ–°ä¸€çº¿åŸå¸‚",
            "similarity_to_target_jd": 90,
            "match_reason": "å²—ä½åŒæ ·èšç„¦å¤§æ¨¡å‹ / æ™ºèƒ½ä½“æ–¹å‘ï¼Œè¦æ±‚ä½ å…·å¤‡äº§å“æ€ç»´ä¸åŸºç¡€æŠ€æœ¯ç†è§£ï¼Œä¸ç°æœ‰é¡¹ç›®éå¸¸å¥‘åˆã€‚",
            "core_requirements": [
                "å‚ä¸ AI äº§å“éœ€æ±‚åˆ†æã€æ–¹æ¡ˆè®¾è®¡ä¸æ–‡æ¡£æ’°å†™",
                "å¯¹ä¸»æµå¤§æ¨¡å‹ / Agent åº”ç”¨æœ‰åŸºæœ¬äº†è§£ï¼Œæœ‰å®è·µç»éªŒæ›´ä½³",
                "è‰¯å¥½çš„æ²Ÿé€šåä½œèƒ½åŠ›ï¼Œèƒ½åœ¨æŠ€æœ¯ä¸ä¸šåŠ¡ä¹‹é—´åšæœ‰æ•ˆå¯¹æ¥"
            ]
        },
        {
            "title": "æ•°æ®äº§å“å®ä¹ ç”Ÿ",
            "company_type": "æ•°æ®æ™ºèƒ½ / ä¼ä¸šæœåŠ¡å…¬å¸ï¼ˆç¤ºä¾‹ï¼‰",
            "location": "åŒ—ä¸Šå¹¿æ·± / æ­å· / æˆéƒ½",
            "similarity_to_target_jd": 85,
            "match_reason": "åœ¨ä¿æŒäº§å“å²—ä½å±æ€§çš„å‰æä¸‹ï¼Œæ›´å¼ºè°ƒæ•°æ®åˆ†æä¸æŒ‡æ ‡è®¾è®¡ï¼Œä¸ä½ çš„ Python / SQL å’Œé¡¹ç›®ç»å†åŒ¹é…åº¦è¾ƒé«˜ã€‚",
            "core_requirements": [
                "å‚ä¸æ•°æ®äº§å“éœ€æ±‚æ¢³ç†ä¸æŒ‡æ ‡ä½“ç³»è®¾è®¡",
                "é…åˆä¸­å° /ä¸šåŠ¡æ–¹æ­å»ºåˆ†ææŠ¥è¡¨ä¸çœ‹æ¿",
                "å…·å¤‡åŸºç¡€ SQL / Python æ•°æ®å¤„ç†èƒ½åŠ›"
            ]
        }
    ],
    "target_jd_overview": [
        {
            "jd_index": 1,
            "jd_title": "JD_1ï¼šAI äº§å“å®ä¹ ç”Ÿï¼ˆç¤ºä¾‹ï¼‰",
            "match_score": 88,
            "recommendation_level": "å¼ºçƒˆæ¨è",
            "short_comment": "å²—ä½æ–¹å‘ä¸ç®€å†ä¸­çš„ AI äº§å“ / æ™ºèƒ½ä½“é¡¹ç›®é«˜åº¦ä¸€è‡´ï¼Œæ˜¯å½“å‰èƒŒæ™¯ä¸‹ä¼˜å…ˆçº§æœ€é«˜çš„é€‰æ‹©ä¹‹ä¸€ã€‚"
        },
        {
            "jd_index": 2,
            "jd_title": "JD_2ï¼šæ•°æ®åˆ†æå®ä¹ ç”Ÿï¼ˆç¤ºä¾‹ï¼‰",
            "match_score": 80,
            "recommendation_level": "å¯é‡ç‚¹è€ƒè™‘",
            "short_comment": "å¼ºè°ƒæ•°æ®åˆ†æèƒ½åŠ›å’Œ SQL / Pythonï¼Œå¯¹ä½ ç°åœ¨çš„æŠ€æœ¯åŸºç¡€æ¯”è¾ƒå‹å¥½ï¼Œä½†äº§å“æˆåˆ†ç•¥å¼±ã€‚"
        }
    ],
    "selected_jd_index": 1
}


def analyze_with_llm(api_key, base_url, model, resume, jd_list):
    """
    resume: ç®€å†æ–‡æœ¬
    jd_list: [{'index': int, 'title': str, 'text': str}, ...]  æ”¯æŒå¤šä¸ª JD
    """
    client = OpenAI(api_key=api_key, base_url=base_url)

    # ç»„åˆå¤š JD å†…å®¹
    jd_blocks = []
    for idx, jd in enumerate(jd_list, start=1):
        title = jd.get("title", f"JD_{idx}")
        text = jd.get("text", "")
        jd_blocks.append(
            f"<<<JD_{idx} - {title}>>>\n{text[:2500]}"
        )
    jd_combined = "\n\n".join(jd_blocks)

    system_prompt = """
ä½ æ˜¯ä¸€åéå¸¸ä¸“ä¸šçš„ã€Œç®€å†è¯„ä¼° + èŒä¸šå‘å±•æ•™ç»ƒã€ï¼Œç†Ÿæ‚‰æ ¡æ‹› / å®ä¹  / ç¤¾æ‹› ATS ç­›é€‰é€»è¾‘ï¼Œ
ç†è§£ AI äº§å“ / æ•°æ®åˆ†æ / äº’è”ç½‘ä¸šåŠ¡å²—ä½çš„çœŸå®å·¥ä½œå†…å®¹å’Œç”¨äººæ ‡å‡†ã€‚

ä½ çš„ç›®æ ‡ï¼š
- å¸®æ±‚èŒè€…çœ‹æ¸…ã€Œå½“å‰ç®€å†ã€ä¸ã€Œå¤šä¸ªå€™é€‰ JDã€çš„åŒ¹é…æƒ…å†µï¼›
- å¸®ä»–é€‰å‡ºæ›´å€¼å¾—é‡ç‚¹å†²åˆºçš„å²—ä½æ–¹å‘ï¼ˆä¸æ›¿ä»–å†³å®šäººç”Ÿï¼Œåªåšä¸“ä¸šå»ºè®®ï¼‰ï¼›
- åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç»™å‡ºç®€å†ä¼˜åŒ–å»ºè®®ã€æœªæ¥3â€“6ä¸ªæœˆçš„æˆé•¿è§„åˆ’ã€å­¦ä¹ èµ„æºæ¨èï¼Œä»¥åŠåŒæ–¹å‘çš„å…¶ä»–å…¬å¸å²—ä½å‚è€ƒã€‚

è¯·æ ¹æ®ã€ç®€å†ã€‘å’Œã€å€™é€‰ JD åˆ—è¡¨ã€‘è¿›è¡Œåˆ†æï¼Œå¹¶è¿”å›ä¸¥æ ¼çš„ JSONï¼Œå­—æ®µå¿…é¡»åŒ…å«ï¼š

1. total_score        (0-100æ•´æ•°)
   - å¯¹ã€Œæœ€ç»ˆé€‰ä¸­çš„ JDã€çš„æ€»ä½“åŒ¹é…åº¦è¯„åˆ†ã€‚

2. dimensions         (å¯¹è±¡ï¼Œé”®åŒ…æ‹¬ï¼š
                        - æŠ€èƒ½åŒ¹é…åº¦
                        - ç»éªŒç›¸å…³æ€§
                        - è¡Œä¸šå¥‘åˆåº¦
                        - è¡¨è¾¾ä¸äº®ç‚¹
                       å€¼ä¸º0-100æ•´æ•°)

3. highlights         (æ•°ç»„ï¼Œ3-5æ¡é«˜åŒ¹é…ç‚¹ï¼Œæ¯æ¡ä¸ºå­—ç¬¦ä¸²ï¼Œè¯­è¨€ä¸“ä¸šã€å…·ä½“ï¼Œé¿å…ç©ºæ´é¸¡æ±¤)

4. gaps               (æ•°ç»„ï¼Œ3-5æ¡ç¼ºå¤±æˆ–é£é™©ç‚¹ï¼Œæ¯æ¡ä¸ºå­—ç¬¦ä¸²ï¼Œå°½é‡å…³è”åˆ°é¢è¯• / ATS ç­›é€‰é£é™©)

5. suggestions        (æ•°ç»„ï¼Œå…ƒç´ ä¸ºå¯¹è±¡ï¼Œå­—æ®µï¼š
                       - section: æ‰€å±æ¨¡å—ï¼Œå¦‚â€œé¡¹ç›®ç»å†â€â€œå®ä¹ ç»å†â€â€œæŠ€èƒ½â€
                       - original: ç®€å†åŸæ–‡å¥å­
                       - problem: å­˜åœ¨çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šç¼ºå°‘é‡åŒ–ç»“æœã€ä¸JDå…³é”®è¯ä¸å¯¹é½ï¼‰
                       - rewrite: å»ºè®®çš„æ”¹å†™ç¤ºä¾‹ï¼ˆæ³¨æ„ä¿æŒçœŸå®ï¼Œä¸è™šæ„ç»å†ï¼‰)

6. draft_resume       (å­—ç¬¦ä¸²ï¼Œé’ˆå¯¹â€œæœ€ç»ˆé€‰ä¸­çš„ JDâ€ç”Ÿæˆçš„å®Œæ•´ç®€å† Markdown æ–‡æœ¬ï¼Œ
                       ä½¿ç”¨ # / ## æ ‡é¢˜å’Œ - åˆ—è¡¨ï¼Œçªå‡ºä¸è¯¥ JD ç›¸å…³çš„ç»å†ä¸æˆæœï¼Œä¸è¦åŒ…å« JSON è½¬ä¹‰å­—ç¬¦)

ã€å¤š JD åŒ¹é…ä¸é€‰æ‹©ã€‘

7. target_jd_overview (æ•°ç»„ï¼Œç”¨äºæ±‡æ€»æ¯ä¸ªå€™é€‰ JD çš„åŒ¹é…æƒ…å†µã€‚æ¯ä¸ªå…ƒç´ ä¸ºå¯¹è±¡ï¼š
                       - jd_index: æ•´æ•°ï¼Œå’Œè¾“å…¥ä¸­çš„ JD åºå·ä¸€è‡´ï¼ˆä» 1 å¼€å§‹ï¼‰
                       - jd_title: å¤åˆ¶è¾“å…¥ä¸­ JD æ ‡é¢˜ï¼ˆå¦‚ï¼šæ–‡ä»¶åæˆ–ä½ çœ‹åˆ°çš„æ ‡é¢˜ï¼‰ï¼Œä¸è¦è‡ªå·±é€ 
                       - match_score: 0-100 æ•´æ•°ï¼Œè¯¥ JD ä¸å½“å‰ç®€å†çš„åŒ¹é…åº¦
                       - recommendation_level: å­—ç¬¦ä¸²ï¼Œå¦‚â€œå¼ºçƒˆæ¨èâ€â€œå¯é‡ç‚¹è€ƒè™‘â€â€œå¯å°è¯•â€â€œä¸æ¨èâ€
                       - short_comment: 1-2 å¥ä¸“ä¸šç‚¹è¯„ï¼Œè¯´æ˜åŒ¹é…å¥½/ä¸å¥½çš„å…³é”®åŸå› )

8. selected_jd_index  (æ•´æ•°ï¼Œä» 1 å¼€å§‹ï¼Œè¡¨ç¤ºä½ è®¤ä¸ºæœ€é€‚åˆåšæœ¬è½®æ·±åº¦ä¼˜åŒ–çš„ JD åºå·ã€‚
                       total_score / dimensions / draft_resume ç­‰éƒ½åº”åŸºäºè¿™ä¸ª JDã€‚)

ã€å­¦ä¹ ä¸èµ„æºæ¨èã€‘

9. learning_plan      (å¯¹è±¡ï¼Œå­—æ®µï¼š
                       - target_direction: ç»¼åˆç®€å†ä¸ JD åæ¨èçš„ä¸»è¦å‘å±•æ–¹å‘ï¼ˆå¦‚ï¼šAIäº§å“ã€æ•°æ®äº§å“ã€æ•°æ®åˆ†æç­‰ï¼‰
                       - summary: ç”¨2-3å¥è¯æ¦‚è¿°æœªæ¥3-6ä¸ªæœˆæ›´ç†æ€§ã€æ›´æœ‰æ•ˆçš„å‡†å¤‡æ€è·¯
                       - skills_to_focus: æ•°ç»„ï¼Œåˆ—å‡º3-6ä¸ªä¼˜å…ˆéœ€è¦è¡¥é½æˆ–åŠ å¼ºçš„èƒ½åŠ›/æŠ€èƒ½
                       - stages: æ•°ç»„ï¼Œæ¯ä¸ªé˜¶æ®µæ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œå­—æ®µï¼š
                           * name: é˜¶æ®µåç§°ï¼Œå¦‚â€œç¬¬1-4å‘¨ï¼šæ‰“åŸºç¡€â€
                           * goals: æ•°ç»„ï¼Œè¯¥é˜¶æ®µçš„ç›®æ ‡ï¼ˆç«™åœ¨æ±‚èŒè€…è§†è§’ï¼Œè€Œä¸æ˜¯ç®—æ³•è§†è§’ï¼‰
                           * actions: æ•°ç»„ï¼Œè¯¥é˜¶æ®µå¯ä»¥æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨å»ºè®®ï¼ˆå¯æ“ä½œï¼Œä¸è¦æ³›æ³›è€Œè°ˆï¼‰)

10. resources         (æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­¦ä¹  / é¢è¯•èµ„æºå»ºè®®å¯¹è±¡ï¼Œå­—æ®µï¼š
                       - platform: å¹³å°åç§°ï¼Œå¦‚â€œBç«™â€â€œYouTubeâ€â€œç‰›å®¢â€â€œCSDNâ€â€œå…¶ä»–â€
                       - category: èµ„æºç±»å‹ï¼Œå¦‚â€œå­¦ä¹ è§†é¢‘â€â€œé¢è¯•ç»éªŒâ€â€œæŠ€æœ¯æ–‡ç« â€â€œåˆ·é¢˜/å®æˆ˜â€
                       - search_keyword: å»ºè®®ç”¨æˆ·åœ¨è¯¥å¹³å°ä½¿ç”¨çš„æœç´¢å…³é”®è¯ï¼ˆå¯ä»¥ç›´æ¥å¤åˆ¶ç²˜è´´å»æœï¼‰
                       - reason: æ¨èç†ç”±ï¼Œè¯´æ˜è¯¥èµ„æºå¦‚ä½•å¸®åŠ©ç”¨æˆ·å¼¥è¡¥å½“å‰ç®€å†ä¸­çš„çŸ­æ¿æˆ–å‡†å¤‡é¢è¯•)

ã€ç›¸ä¼¼å²—ä½æ¨èï¼ˆåŒæ–¹å‘ï¼‰ã€‘

11. job_recommendations (æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå²—ä½æ¨èå¯¹è±¡ï¼Œå­—æ®µï¼š
                       - title: å²—ä½åç§°ï¼Œä¾‹å¦‚â€œAI äº§å“å®ä¹ ç”Ÿâ€â€œæ•°æ®äº§å“å®ä¹ ç”Ÿâ€
                       - company_type: å…¬å¸ç±»å‹æˆ–ç¤ºä¾‹æè¿°ï¼Œå¦‚â€œä¸€çº¿äº’è”ç½‘å…¬å¸ï¼ˆç¤ºä¾‹ï¼‰â€â€œæ•°æ®æ™ºèƒ½å…¬å¸ï¼ˆç¤ºä¾‹ï¼‰â€
                       - location: åŸå¸‚æˆ–åœ°åŒºï¼ˆå¯ä»¥æ˜¯æ¨¡ç³Šæè¿°ï¼Œå¦‚â€œä¸€çº¿/æ–°ä¸€çº¿åŸå¸‚â€ï¼‰
                       - similarity_to_target_jd: 0-100æ•´æ•°ï¼Œè¡¨ç¤ºä¸ã€Œæœ€ç»ˆé€‰ä¸­ JDã€çš„ç›¸ä¼¼ç¨‹åº¦
                       - match_reason: æ¨èç†ç”±ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆè¯¥å²—ä½æ–¹å‘é€‚åˆå½“å‰ç”¨æˆ·ï¼ˆç»“åˆç®€å†ä¸JDï¼‰
                       - core_requirements: æ•°ç»„ï¼Œåˆ—å‡º3-6æ¡è¯¥å²—ä½æ ¸å¿ƒè¦æ±‚ç¤ºä¾‹ï¼ˆç”¨è‡ªç„¶è¯­è¨€ï¼‰

å¼ºçº¦æŸè¦æ±‚ï¼š
- æ‰€æœ‰ job_recommendations å¿…é¡»ä¸ã€Œå€™é€‰ JD çš„å²—ä½ç±»å‹ã€åŒä¸€èŒä¸šæ—ï¼Œä¾‹å¦‚ï¼š
  - è¾“å…¥ JD æ˜¯ AI äº§å“ / æ•°æ®äº§å“ / äº’è”ç½‘äº§å“å²—ï¼Œåªèƒ½æ¨èåŒç±»æˆ–é«˜åº¦ç›¸å…³äº§å“/æ•°æ®å²—ï¼›
  - ä¸è¦è·¨åˆ°ã€Œè´¢åŠ¡ã€äººåŠ›ã€çº¯åç«¯å¼€å‘ã€ç­‰å®Œå…¨ä¸ç›¸å…³æ–¹å‘ã€‚
- ä¸è¦æœæ’°å…·ä½“å…¬å¸åå’Œå…·ä½“æ‹›è˜é“¾æ¥ï¼Œå¯ä»¥ä½¿ç”¨â€œæŸå¤´éƒ¨äº’è”ç½‘å…¬å¸ï¼ˆç¤ºä¾‹ï¼‰â€è¿™ç±»æ³›åŒ–æè¿°ã€‚
- æ‰€æœ‰å†…å®¹å¿…é¡»åŸºäºã€ç®€å†ã€‘å’Œã€å€™é€‰ JDã€‘çš„æ–¹å‘ã€æŠ€èƒ½å·®è·æ¥ç”Ÿæˆï¼Œé¿å…å’Œç”¨æˆ·å®Œå…¨æ— å…³çš„å»ºè®®ã€‚
- ä¸è¦ç¼–é€ ç®€å†ä¸­æ ¹æœ¬ä¸å­˜åœ¨çš„å­¦æ ¡ / å…¬å¸ / è¯ä¹¦ï¼Œå¯ä»¥åˆç†æ¨æµ‹é€‚åˆçš„å­¦ä¹ æ–¹å‘å’Œèµ„æºå…³é”®è¯ã€‚
- è¯­æ°”ä¸“ä¸šã€å‹å¥½ï¼Œå°½é‡ç«™åœ¨æ±‚èŒè€…è§†è§’ï¼Œé¿å…ç©ºæ³›é¸¡æ±¤ï¼Œå¤šç»™å¯æ‰§è¡Œå»ºè®®ã€‚
- è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼åˆæ³•çš„ JSONï¼Œå¯¹è±¡æœ€å¤–å±‚å¿…é¡»åŒ…å«ä¸Šè¿°æ‰€æœ‰å­—æ®µã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": (
                        f"ã€ç®€å†æ–‡æœ¬ã€‘:\n{resume[:4000]}\n\n"
                        f"ã€å€™é€‰å²—ä½JDåˆ—è¡¨ã€‘ï¼ˆæœ€å¤šæˆªå–å‰2500å­—ç¬¦/æ¡ï¼‰ï¼š\n\n{jd_combined}"
                    )
                }
            ],
            response_format={"type": "json_object"},
            temperature=0.7
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"API è°ƒç”¨é”™è¯¯: {e}")
        return None


# ================= 4. UI ç•Œé¢æ„å»º =================

# --- Sidebar: é…ç½® ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")

    config_mode = st.radio("è¿è¡Œæ¨¡å¼", ["DeepSeek (æ¨è)", "OpenAI / å…¶ä»–", "æ¼”ç¤ºæ¨¡å¼ (Demo)"])

    if config_mode == "DeepSeek (æ¨è)":
        st.info("ğŸ’¡ é«˜æ€§ä»·æ¯”ï¼Œé€»è¾‘èƒ½åŠ›å¼º")
        api_key = st.text_input("DeepSeek API Key", type="password")
        base_url = "https://api.deepseek.com"
        model_name = "deepseek-chat"
    elif config_mode == "OpenAI / å…¶ä»–":
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value="https://api.openai.com/v1")
        model_name = st.text_input("Model Name", value="gpt-4o")
    else:
        api_key = "demo"
        base_url = ""
        model_name = "demo"

    st.markdown("---")
    st.markdown("### ä½¿ç”¨æŒ‡å—")
    st.markdown("1. ä¸Šä¼ ç®€å† (PDF/Word/å›¾ç‰‡)")
    st.markdown("2. ç²˜è´´æˆ–ä¸Šä¼  1â€“N ä¸ª JDï¼ˆæ–‡æœ¬/æ–‡ä»¶/å›¾ç‰‡ï¼‰")
    st.markdown("3. ç‚¹å‡»åˆ†æ")
    st.markdown("4. æŸ¥çœ‹åŒ¹é…æŠ¥å‘Š + å­¦ä¹ å»ºè®® + å²—ä½æ¨èå¹¶ä¸‹è½½ç®€å†")

# --- Main Area ---
st.title("ğŸ’¼ JobAlign AI Pro | èŒé…åŠ©æ‰‹")
st.caption("å¤šå²—ä½åŒ¹é… + ç®€å†ä¼˜åŒ– + å­¦ä¹ è§„åˆ’ + å²—ä½æ¨èï¼Œä¸€æ¬¡èµ°å®Œã€‚")

col1, col2 = st.columns(2)

# ========= 4.1 ç®€å†è¾“å…¥ =========
with col1:
    st.subheader("1. ä¸ªäººç®€å†")
    resume_file = st.file_uploader(
        "ä¸Šä¼ ç®€å†ï¼ˆæ”¯æŒ PDF / Word / æ–‡æœ¬ / å›¾ç‰‡ï¼‰",
        type=['pdf', 'docx', 'doc', 'txt', 'png', 'jpg', 'jpeg', 'bmp', 'tiff', 'gif']
    )
    resume_text = ""
    if resume_file:
        resume_text = DocumentHandler.extract_text(resume_file)
        if resume_text.startswith("Error: æ–‡ä»¶è§£æå¤±è´¥"):
            st.error(resume_text)
        else:
            st.success(f"âœ… å·²æå–çº¦ {len(resume_text)} å­—")
            with st.expander("æŸ¥çœ‹ç®€å†è§£æå†…å®¹"):
                st.text(resume_text[:800] + "..." if len(resume_text) > 800 else resume_text)
    else:
        resume_text = st.text_area("æˆ–ç›´æ¥ç²˜è´´ç®€å†å†…å®¹", height=200)

# ========= 4.2 å¤š JD è¾“å…¥ =========
with col2:
    st.subheader("2. ç›®æ ‡å²—ä½ (JD) â€” å¯ä¸€æ¬¡ä¸Šä¼ å¤šä¸ª")
    jd_input_method = st.radio("è¾“å…¥æ–¹å¼", ["æ–‡æœ¬ç²˜è´´ï¼ˆå•ä¸ªï¼‰", "æ–‡ä»¶ä¸Šä¼ ï¼ˆå¯å¤šä¸ªï¼‰"], horizontal=True)
    jd_entries = []

    if jd_input_method == "æ–‡æœ¬ç²˜è´´ï¼ˆå•ä¸ªï¼‰":
        jd_text = st.text_area(
            "ç²˜è´´èŒä½æè¿°ï¼ˆå•ä¸ª JDï¼‰",
            height=220,
            placeholder="èŒä½æè¿°\nå²—ä½èŒè´£...\nä»»èŒè¦æ±‚..."
        )
        if jd_text.strip():
            jd_entries.append({
                "index": 1,
                "title": "æ–‡æœ¬JD",
                "text": jd_text
            })
    else:
        jd_files = st.file_uploader(
            "ä¸Šä¼  JD æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼Œæ”¯æŒ PDF / Word / æ–‡æœ¬ / å›¾ç‰‡ï¼‰",
            type=['pdf', 'docx', 'doc', 'txt', 'png', 'jpg', 'jpeg', 'bmp', 'tiff', 'gif'],
            accept_multiple_files=True
        )
        if jd_files:
            for idx, jf in enumerate(jd_files, start=1):
                text = DocumentHandler.extract_text(jf)
                if text.startswith("Error: æ–‡ä»¶è§£æå¤±è´¥"):
                    st.error(f"âŒ JD æ–‡ä»¶è§£æå¤±è´¥ï¼š{jf.name}ï¼Œè¯·æ£€æŸ¥åé‡è¯•ã€‚")
                    continue
                jd_entries.append({
                    "index": idx,
                    "title": jf.name,
                    "text": text
                })
            if jd_entries:
                st.success(f"âœ… å·²æˆåŠŸå¯¼å…¥ {len(jd_entries)} ä¸ª JD")
                with st.expander("æŸ¥çœ‹éƒ¨åˆ† JD å†…å®¹é¢„è§ˆ"):
                    for entry in jd_entries:
                        st.markdown(f"**[{entry['index']}] {entry['title']}**")
                        preview = entry['text']
                        st.text(preview[:400] + "..." if len(preview) > 400 else preview)
                        st.markdown("<hr style='margin: 4px 0; opacity: 0.3'/>", unsafe_allow_html=True)

st.markdown("---")

# æäº¤æŒ‰é’®
btn_col1, btn_col2, btn_col3 = st.columns([1, 2, 1])
with btn_col2:
    analyze_btn = st.button(
        "ğŸš€ å¼€å§‹æ·±åº¦åˆ†æï¼šå¤š JD åŒ¹é… + ç®€å†ä¼˜åŒ– + å­¦ä¹ å»ºè®® + å²—ä½æ¨è",
        use_container_width=True
    )

# é€»è¾‘å¤„ç†
if analyze_btn:
    if not resume_text or not resume_text.strip():
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æˆ–ç²˜è´´ç®€å†ã€‚")
    elif not jd_entries:
        st.warning("âš ï¸ è¯·è‡³å°‘æä¾› 1 ä¸ª JDï¼ˆå¯å¤šé€‰ï¼‰ã€‚")
    elif config_mode != "æ¼”ç¤ºæ¨¡å¼ (Demo)" and not api_key:
        st.error("âš ï¸ è¯·è¾“å…¥ API Key æ‰èƒ½ä½¿ç”¨ AI åŠŸèƒ½ã€‚")
    else:
        with st.spinner("ğŸ¤– AI æ­£åœ¨é˜…è¯»ä½ çš„ç®€å† & å¤šä¸ª JDï¼Œå¹¶ç”ŸæˆåŒ¹é…æŠ¥å‘Šä¸æˆé•¿å»ºè®®..."):
            if config_mode == "æ¼”ç¤ºæ¨¡å¼ (Demo)":
                time.sleep(2)
                result = MOCK_DATA
            else:
                result = analyze_with_llm(api_key, base_url, model_name, resume_text, jd_entries)

            if result:
                st.session_state.result_json = result
                st.session_state.analyzed = True
                st.rerun()

# ================= 5. ç»“æœå±•ç¤º =================
if st.session_state.analyzed and st.session_state.result_json:
    res = st.session_state.result_json

    # ----- 5.1 å¤š JD åŒ¹é…æ¦‚è§ˆ -----
    st.header("ğŸ“Œ å¤šå²—ä½åŒ¹é…æ¦‚è§ˆ")
    jd_overview = res.get("target_jd_overview", [])
    selected_jd_index = res.get("selected_jd_index", None)

    if jd_overview:
        df_jd = pd.DataFrame([
            {
                "åºå·": item.get("jd_index"),
                "å²—ä½åç§°": item.get("jd_title"),
                "åŒ¹é…åˆ†": item.get("match_score"),
                "æ¨èçº§åˆ«": item.get("recommendation_level"),
                "ç‚¹è¯„": item.get("short_comment")
            }
            for item in jd_overview
        ])
        st.dataframe(df_jd, use_container_width=True)

        if selected_jd_index:
            selected_row = next(
                (item for item in jd_overview if item.get("jd_index") == selected_jd_index),
                None
            )
            if selected_row:
                st.success(
                    f"æœ¬è½®è¯¦ç»†ä¼˜åŒ–åŸºäºï¼šç¬¬ {selected_jd_index} ä¸ªå²—ä½ â€”â€” {selected_row.get('jd_title', '')}"
                )
    else:
        st.info("æš‚æ— å¤š JD åŒ¹é…æ¦‚è§ˆæ•°æ®ã€‚")

    st.markdown("---")

    # ----- 5.2 åŒ¹é…åˆ† & äº®ç‚¹ / ç¼ºå¤± -----
    st.header("ğŸ“Š é’ˆå¯¹é€‰ä¸­ JD çš„åŒ¹é…æŠ¥å‘Š")
    m_col1, m_col2 = st.columns([1, 1])

    with m_col1:
        st.metric("æ€»ä½“åŒ¹é…å¾—åˆ†", res.get('total_score', 0), delta_color="normal")
        # é›·è¾¾å›¾
        dimensions = res.get('dimensions', {})
        if dimensions:
            df_radar = pd.DataFrame(dict(
                r=list(dimensions.values()),
                theta=list(dimensions.keys())
            ))
            fig = px.line_polar(df_radar, r='r', theta='theta', line_close=True, range_r=[0, 100])
            fig.update_traces(fill='toself')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— ç»´åº¦è¯„åˆ†æ•°æ®ã€‚")

    with m_col2:
        st.subheader("ğŸ¯ æ ¸å¿ƒå‘ç°")
        tab_high, tab_gap = st.tabs(["âœ¨ äº®ç‚¹ (Highlights)", "âš ï¸ ç¼ºå¤± / é£é™© (Gaps)"])
        with tab_high:
            for i in res.get('highlights', []):
                st.success(f"â€¢ {i}")
        with tab_gap:
            for i in res.get('gaps', []):
                st.error(f"â€¢ {i}")

    st.markdown("---")

    # ----- 5.3 æ™ºèƒ½æ”¹å†™å»ºè®® -----
    st.subheader("ğŸ’¡ æ™ºèƒ½æ”¹å†™å»ºè®®ï¼ˆé€æ¡å¯¹æ¯”ï¼‰")
    suggestions = res.get('suggestions', [])
    if suggestions:
        for item in suggestions:
            with st.container():
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown(f"**ğŸ”´ åŸæ–‡ ({item.get('section', 'æœªæ ‡æ³¨æ¨¡å—')})**")
                    st.caption(f"é—®é¢˜ï¼š{item.get('problem', 'æœªæä¾›é—®é¢˜è¯´æ˜')}")
                    st.text(item.get('original', ''))
                with c2:
                    st.markdown("**ğŸŸ¢ ä¼˜åŒ–åç¤ºä¾‹**")
                    st.info(item.get('rewrite', ''))
                st.markdown("<hr style='margin: 5px 0; opacity: 0.3'/>", unsafe_allow_html=True)
    else:
        st.info("æš‚æ— æ”¹å†™å»ºè®®ã€‚")

    st.markdown("---")

    # ----- 5.4 ç›¸ä¼¼å²—ä½æ¨è -----
    job_recs = res.get("job_recommendations", [])
    if job_recs:
        st.header("ğŸ” ç›¸å…³å²—ä½æ¨èï¼ˆåŒæ–¹å‘ï¼‰")
        st.caption("ä»¥ä¸‹ä¸ºåŒä¸€èŒä¸šæ–¹å‘ä¸‹çš„ç¤ºä¾‹å²—ä½ç”»åƒï¼Œæ–¹ä¾¿ä½ æ‹“å±•å¯æŠ•é€’çš„å…¬å¸ä¸èŒä½æ–¹å‘ã€‚")
        for job in job_recs:
            with st.container():
                title = job.get("title", "æœªçŸ¥å²—ä½")
                company_type = job.get("company_type", "")
                location = job.get("location", "")
                similarity = job.get("similarity_to_target_jd", None)
                match_reason = job.get("match_reason", "")
                core_reqs = job.get("core_requirements", [])

                st.markdown(f"**{title}**")
                meta = []
                if company_type:
                    meta.append(company_type)
                if location:
                    meta.append(location)
                if isinstance(similarity, (int, float)):
                    meta.append(f"ä¸å½“å‰ç›®æ ‡ JD ç›¸ä¼¼åº¦çº¦ {similarity} åˆ†")
                if meta:
                    st.caption(" Â· ".join(meta))
                if match_reason:
                    st.write(match_reason)
                if core_reqs:
                    st.markdown("æ ¸å¿ƒè¦æ±‚ç¤ºä¾‹ï¼š")
                    for r_item in core_reqs:
                        st.write(f"- {r_item}")
                st.markdown("<hr style='margin: 5px 0; opacity: 0.15'/>", unsafe_allow_html=True)

    st.markdown("---")

    # ----- 5.5 å­¦ä¹ ä¸æˆé•¿å»ºè®® -----
    learning_plan = res.get("learning_plan")
    if learning_plan:
        st.header("ğŸ“š å­¦ä¹ ä¸æˆé•¿å»ºè®®ï¼ˆæœªæ¥ 3â€“6 ä¸ªæœˆå‚è€ƒï¼‰")
        st.subheader(f"æ¨èå‘å±•æ–¹å‘ï¼š{learning_plan.get('target_direction', 'æœªè¯†åˆ«')}")
        summary = learning_plan.get('summary')
        if summary:
            st.write(summary)

        skills_to_focus = learning_plan.get('skills_to_focus', [])
        if skills_to_focus:
            st.markdown("**ä¼˜å…ˆå…³æ³¨çš„èƒ½åŠ› / æŠ€èƒ½ï¼š**")
            for s in skills_to_focus:
                st.write(f"- {s}")

        stages = learning_plan.get('stages', [])
        if stages:
            st.markdown("**é˜¶æ®µæ€§è¡ŒåŠ¨å»ºè®®ï¼š**")
            for stage in stages:
                with st.expander(stage.get('name', 'æœªå‘½åé˜¶æ®µ'), expanded=False):
                    goals = stage.get('goals', [])
                    actions = stage.get('actions', [])
                    if goals:
                        st.markdown("ğŸ“Œ é˜¶æ®µç›®æ ‡ï¼š")
                        for g in goals:
                            st.write(f"- {g}")
                    if actions:
                        st.markdown("ğŸ§­ æ¨èè¡ŒåŠ¨ï¼š")
                        for a in actions:
                            st.write(f"- {a}")
    else:
        st.info("æš‚æ— å­¦ä¹ è§„åˆ’æ•°æ®ã€‚")

    st.markdown("---")

    # ----- 5.6 å­¦ä¹ èµ„æº & é¢ç»æ¨è -----
    resources = res.get("resources", [])
    if resources:
        st.header("ğŸ¥ å­¦ä¹ èµ„æº & é¢è¯•ç»éªŒæ¨è")
        st.caption("ä»¥ä¸‹ä¸ºã€Œå¹³å° + æœç´¢å…³é”®è¯ã€å½¢å¼ï¼Œå»ºè®®å¤åˆ¶å…³é”®è¯åˆ°å¯¹åº”å¹³å°æœç´¢æœ€æ–°å†…å®¹ã€‚")
        for r in resources:
            with st.container():
                platform = r.get('platform', 'å…¶ä»–')
                category = r.get('category', '')
                search_keyword = r.get('search_keyword', '')
                reason = r.get('reason', '')

                st.markdown(f"**{platform} Â· {category}**")
                if search_keyword:
                    st.markdown("æ¨èæœç´¢å…³é”®è¯ï¼š")
                    st.code(search_keyword, language="text")
                if reason:
                    st.caption(reason)
                st.markdown("<hr style='margin: 5px 0; opacity: 0.2'/>", unsafe_allow_html=True)
    else:
        st.info("æš‚æ— èµ„æºæ¨èæ•°æ®ã€‚")

    st.markdown("---")

    # ----- 5.7 ç®€å†ç”Ÿæˆä¸å¯¼å‡º -----
    st.header("ğŸ“ å®šåˆ¶ç‰ˆç®€å†é¢„è§ˆä¸å¯¼å‡º")

    draft_resume = res.get('draft_resume', '')
    if draft_resume:
        # ç”Ÿæˆ Word æ–‡æ¡£
        docx_file = WordGenerator.create_docx_from_markdown(draft_resume)

        # å¯¼å‡ºæŒ‰é’®
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ Word (.docx) ç®€å†",
            data=docx_file,
            file_name=f"JobAlign_å®šåˆ¶ç®€å†.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

        with st.expander("æŸ¥çœ‹ / ç¼–è¾‘ç®€å† Markdown æºç "):
            st.text_area("ç®€å† Markdown æºç ", value=draft_resume, height=400)
    else:
        st.info("æš‚æ— å®šåˆ¶ç®€å†å†…å®¹ã€‚")
